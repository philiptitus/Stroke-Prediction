# 🧠 Stroke Prediction Models  

This project utilizes Kaggle's stroke prediction dataset to develop and compare three decision tree-based machine learning models:  

1. **XGBoost**  
2. **Random Forest**  
3. **Decision Tree (scikit-learn)**  

## 📂 Project Structure  

- 📜 **`model.ipynb`** – Jupyter Notebook containing the implementation and comparison of the three models.  
- 📜 **`README.md`** – Project documentation.  
- 📜 **`requirements.txt`** – List of dependencies required to run the project.  

## ⚙️ Installation  

Ensure you have Python installed, then install the required dependencies using:  

```bash
pip install -r requirements.txt
```  

## 🚀 Usage  

1. Open **`model.ipynb`** in **Jupyter Notebook** or **JupyterLab**.  
2. Run the notebook cells to train, evaluate, and compare the models.  
3. Analyze the results and accuracy metrics.  

## 📊 Conclusion  

Based on the accuracy results:  

✅ **XGBoost** provides the highest accuracy.  
✅ **Random Forest** performs well but is slightly less accurate than XGBoost.  
⚠️ **Decision Tree** has the lowest accuracy among the three models.  

## 📁 Dataset  

The dataset used in this project is the **Stroke Prediction Dataset** from Kaggle. You can access it [here](https://www.kaggle.com).  

## 📜 License  

This project is licensed under the **MIT License**.  
